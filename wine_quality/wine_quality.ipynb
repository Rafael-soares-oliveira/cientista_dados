{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import model_selection as ms\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import\n",
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "**Contextualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measurements of 11 physical-chemical variables that characterize each sample (the features of the problem):\n",
    "<br>\n",
    "  - 1 - fixed acidity - measurement of acidity due to the presence of low-volatility organic acids (malic, lactic, tartaric or citric acid);\n",
    "  - 2 - volatile acidity - measurement of acidity due to the presence of low molecular weight acids (mainly acetic acid), which are responsible for the vinegar aroma and taste;\n",
    "  - 3 - citric acid - measurement of citric acid;\n",
    "  - 4 - residual sugar - measurement of residual sugar present, originating from the sugar residues of the grape that remain after the end of fermentation;\n",
    "  - 5 - chlorides - measurement of chlorides (chlorine ions);\n",
    "  - 6 - free sulfur dioxide - measurement of free sulfur dioxide (i.e., that which is not bound to other molecules); - 7 - total sulfur dioxide - measure of total sulfur dioxide (free + portion bound to other molecules);\n",
    "  - 8 - density - measure of the density of the wine;\n",
    "  - 9 - pH - measure of the pH of the wine;\n",
    "  - 10 - sulphates - measure of sulfates (SO₄²⁻ ions);\n",
    "  - 11 - alcohol - measure of the alcoholic strength.\n",
    "  - 12 - quality - numerical quality score (from 3 to 8), produced based on sensory data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "1. The main descriptive statistics of position (mean, median, quartiles etc.) and dispersion (std, IQR etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc.loc[\"IQR\"] = df_desc.loc[\"75%\"] - df_desc.loc[\"25%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"quality\")\n",
    "Y = df[\"quality\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "  'Feature': X.columns,\n",
    "  'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "2. Presence of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "  plt.figure(figsize=(4,4))\n",
    "  sns.histplot(data=df, x=col, kde=True).set_title(f\"Variable distribution: {col}\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Método do Quartil.\n",
    "\n",
    "for col in df.drop(columns='quality'):\n",
    "    \n",
    "  Q1 = df[col].quantile(0.25)\n",
    "  Q3 = df[col].quantile(0.75)\n",
    "  IQR = Q3 - Q1\n",
    "  \n",
    "  aux_outliers = df[\n",
    "    (df[col] < Q1-(IQR*1.5)) |\n",
    "    (df[col] > Q3+(IQR*1.5))\n",
    "  ]\n",
    "  \n",
    "  indices_outliers = aux_outliers.index.tolist()\n",
    "  \n",
    "  if len(indices_outliers) >= 1:\n",
    "      \n",
    "    print(f\"The column {col} has {len(indices_outliers)} outliers!\")\n",
    "    print(\"\\nIts indexes are:\\n\")\n",
    "    print(indices_outliers)\n",
    "\n",
    "  else:\n",
    "      \n",
    "    print(f\"The column {col} has not outliers!\")\n",
    "      \n",
    "  print()\n",
    "  print(\"=\"*80)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "3. Bar graph of the 90% confidence interval for the mean of each of the physical-chemical variables, grouped by the categorical levels of the response variable quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fixed acidity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for col in df.drop(columns=\"quality\"):\n",
    "  sns.barplot(data=df, x=\"quality\", y=col, errorbar=(\"ci\", 90), hue=\"quality\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality_bin'] = df['quality'].apply(lambda x : \"bom\" if x > 5 else \"ruim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df.drop(columns=['quality'])\n",
    "df_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_bin.drop(columns='quality_bin'):\n",
    "  sns.histplot(\n",
    "    data=df_bin, x=col, kde=True, hue=df_bin['quality_bin']\n",
    "    ).set_title(f\"Distribuição da variável {col}\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "4. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.title(\n",
    "  \"Correlation\".upper(),\n",
    "  fontdict={'family':'calibri', 'fontsize':18, 'weight':'bold', 'color':'red'},\n",
    "  pad=20\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation with quality column:\".center(50).upper())\n",
    "print()\n",
    "for col in df.drop(columns=\"quality\").columns:\n",
    "  print(f\"{col}: {df[\"quality\"].corr(df[col]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(\n",
    "  sampling_strategy='minority',\n",
    "  random_state=42,\n",
    "  n_neighbors=5\n",
    ")\n",
    "\n",
    "# Division between independent and dependent variables\n",
    "X = df.drop(columns=[\"quality\"])\n",
    "y = df[\"quality\"].values\n",
    "\n",
    "# Cubic Root to reduce outliers. Presents a similar result to when using logarithm\n",
    "X = X.map(lambda x: x**(1/3))\n",
    "\n",
    "# Robust to outliers\n",
    "scaler = preprocessing.RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Oversampling using ADASYN, shows a better result than SMOTE\n",
    "X, y = adasyn.fit_resample(X, y)\n",
    "\n",
    "# Reduce to 10 features. Shows better result\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Build Random Forest Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameters to iterate\n",
    "param_grid = [\n",
    "  {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Execute GridSearch and Train Model\n",
    "grid_search = ms.GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Values\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Build confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "print(\"Model Accuracy:\")\n",
    "print(f\"{round(accuracy * 100,2)}%\")\n",
    "print()\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix to evaluate model\n",
    "font_ticklabels = FontProperties(\n",
    "  family='calibri', size=12, weight='bold')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "ax_rf = sns.heatmap(\n",
    "  conf_matrix,\n",
    "  annot=True,\n",
    "  fmt='d',\n",
    "  cmap='Blues',\n",
    "  xticklabels=set(y_train),\n",
    "  yticklabels=set(y_train),\n",
    "  cbar=False # Remove color bar\n",
    ")\n",
    "\n",
    "plt.xticks(fontproperties=font_ticklabels)\n",
    "plt.yticks(fontproperties=font_ticklabels)\n",
    "\n",
    "plt.xlabel('Predicted', fontdict={'fontsize':14}, labelpad=20)\n",
    "plt.ylabel('Test', fontdict={'fontsize':14}, labelpad=20)\n",
    "plt.title('Confusion Matrix', fontdict={'fontsize':16})\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize curve\n",
    "for col in pd.DataFrame(X):\n",
    "  sns.kdeplot(data=pd.DataFrame(X), x=col).set_title(f\"Variable distribution: {col}\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificação de contaminação após transformação cúbica\n",
    "\n",
    "# Valores de contaminação a serem testados\n",
    "contamination_values = [0.001, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Avaliando o desempenho do modelo para cada valor de contaminação\n",
    "for classe in set(df[\"quality\"].unique()):\n",
    "  print(f\"Class: {classe}\")\n",
    "  for contamination in contamination_values:\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_train[y_train == classe])\n",
    "    y_pred = model.predict(X_test[y_test == classe])\n",
    "    precision = precision_score(y_test[y_test == classe], y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test[y_test == classe], y_pred, average='macro', zero_division=0)\n",
    "    print(f'Contamination: {contamination}, Precision: {precision}, Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "5. Quality reduced to 'Bad' or 'Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"quality\"] = df[\"quality\"].apply(lambda x: 0 if x <= 5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of each quality\n",
    "df2[\"quality\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Gain\n",
    "X = df2.drop(columns=\"quality\")\n",
    "Y = df2[\"quality\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "  'Feature': X.columns,\n",
    "  'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df2.corr(), annot=True)\n",
    "plt.title(\n",
    "  \"Correlation\".upper(),\n",
    "  fontdict={'family':'calibri', 'fontsize':18, 'weight':'bold', 'color':'red'},\n",
    "  pad=20\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division between independent and dependent variables\n",
    "X = df2.drop(columns=[\"quality\"])\n",
    "y = df2[\"quality\"].values\n",
    "\n",
    "# Cubic Root to reduce outliers.\n",
    "X = X.map(lambda x: x**(1/3))\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reduce to 10 features. Shows better result\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X,\n",
    "  y,\n",
    "  test_size=0.2,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "  'n_estimators': [50, 100, 200],\n",
    "  'max_depth': [None, 10, 20],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Treina o Stacking Classifier\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Values\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Build confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "print(\"Model Accuracy:\")\n",
    "print(f\"{round(accuracy * 100,2)}%\")\n",
    "print()\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix to evaluate model\n",
    "font_ticklabels = FontProperties(\n",
    "  family='calibri', size=12, weight='bold')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "ax_rf = sns.heatmap(\n",
    "  conf_matrix,\n",
    "  annot=True,\n",
    "  fmt='d',\n",
    "  cmap='Blues',\n",
    "  xticklabels=set(y_train),\n",
    "  yticklabels=set(y_train),\n",
    "  cbar=False # Remove color bar\n",
    ")\n",
    "\n",
    "plt.xticks(fontproperties=font_ticklabels)\n",
    "plt.yticks(fontproperties=font_ticklabels)\n",
    "\n",
    "plt.xlabel('Predicted', fontdict={'fontsize':14}, labelpad=20)\n",
    "plt.ylabel('Test', fontdict={'fontsize':14}, labelpad=20)\n",
    "plt.title('Confusion Matrix', fontdict={'fontsize':16})\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
