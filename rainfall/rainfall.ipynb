{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objects as go\n",
    "from plotly import express as px\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    ")\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    ")\n",
    "\n",
    "# Models\n",
    "import xgboost as xgb\n",
    "\n",
    "# Verifiy GPU\n",
    "import cupy as cp\n",
    "\n",
    "# Exporting model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Import</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Statistics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = df_train.describe()\n",
    "df_describe.loc[\"IQR\"] = df_describe.loc[\"75%\"] - df_describe.loc[\"25%\"]\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Density Plot</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1 style=\"font-size: 18px;\">For each Rainfall Status</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot(df, col, target, ax):\n",
    "    \"\"\"Density plot for each column\"\"\"\n",
    "    sns.kdeplot(df[df[target] == 0][col], ax=ax, color=\"blue\", label=\"No Rainfall\")\n",
    "    sns.kdeplot(df[df[target] == 1][col], ax=ax, color=\"red\", label=\"Rainfall\")\n",
    "\n",
    "    ax.axvline(df[col].mean(), color=\"black\", linestyle=\"--\", label=\"Mean\")\n",
    "    ax.axvline(df[col].median(), color=\"green\", linestyle=\"--\", label=\"Median\")\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "# Create a figure with 5 rows and 2 columns\n",
    "fig, axes = plt.subplots(figsize=(15, 25), nrows=5, ncols=2)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each column in a separate subplot\n",
    "for i, col in enumerate(df_train.drop(columns=[\"day\", \"rainfall\"]).columns):\n",
    "    density_plot(df_train, col, \"rainfall\", axes[i])\n",
    "plt.suptitle(\"Density Plot for Each Rainfall Status\", y=1, fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1 style=\"font-size: 18px;\">All</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot(df):\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(15, 25), nrows=5, ncols=2)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    def density_plot(col, axes):\n",
    "        \"\"\"Density plot for each column\"\"\"\n",
    "        sns.kdeplot(df[col], ax=axes, color=\"blue\", label=\"Rainfall\")\n",
    "\n",
    "        axes.axvline(df[col].mean(), color=\"black\", linestyle=\"--\", label=\"Mean\")\n",
    "        axes.axvline(df[col].median(), color=\"green\", linestyle=\"--\", label=\"Median\")\n",
    "\n",
    "        axes.legend()\n",
    "\n",
    "    # Plot each column in a separate subplot\n",
    "    for i, col in enumerate(df.drop(columns=[\"day\", \"rainfall\"]).columns):\n",
    "        density_plot(col, axes[i])\n",
    "\n",
    "    plt.suptitle(\"Density Plot All Data\", y=1, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_plot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled = df_train.copy()\n",
    "df_train_scaled[df_train.drop(columns=[\"day\", \"rainfall\"]).columns] = df_train.drop(columns=[\"day\", \"rainfall\"]).apply(np.log1p)\n",
    "\n",
    "density_plot(df_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Correlation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df_train.corr(\"spearman\"), annot=True)\n",
    "plt.title(\n",
    "    \"Correlation\".upper(),\n",
    "    fontdict={\"family\": \"calibri\", \"fontsize\": 18, \"weight\": \"bold\", \"color\": \"red\"},\n",
    "    pad=20,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Matrix Scatter Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "fig = px.scatter_matrix(\n",
    "    df_train,\n",
    "    dimensions=[col for col in df_train.drop(columns=[\"day\", \"rainfall\"]).columns],\n",
    "    color=\"rainfall\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Scatter Matrix\",\n",
    "    title_font_family=\"calibri\",\n",
    "    title_font_size=30,\n",
    "    title_font_color=\"black\",\n",
    "    title_font_weight=\"bold\",\n",
    "    title_x=0.5,\n",
    "    title_y=1,\n",
    "    title_pad_t=20,\n",
    "    height=1200,\n",
    "    width=1200,\n",
    ")\n",
    "\n",
    "# Remover a barra de cores, mas manter a divisão de cores\n",
    "fig.update_coloraxes(showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">BoxPlot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "cols = df_train.drop(columns=[\"day\", \"rainfall\"]).columns\n",
    "visible = [False] * (len(cols))\n",
    "\n",
    "# Criando um boxplot para cada coluna, excluindo \"day\" e \"rainfall\"\n",
    "for col in cols:\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=df_train[df_train[\"rainfall\"] == 0][col],\n",
    "            name=f\"{col} - No Rainfall\",\n",
    "            visible=(col == cols[0]),\n",
    "            hovertemplate=\"<b>%{x}:</b> %{y:.2f}<extra></extra>\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=df_train[df_train[\"rainfall\"] == 1][col],\n",
    "            name=f\"{col} - Rainfall\",\n",
    "            visible=(col == cols[0]),\n",
    "            hovertemplate=\"<b>%{x}:</b> %{y:.2f}<extra></extra>\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "buttons =[\n",
    "    dict(\n",
    "        label=col,\n",
    "        method=\"update\",\n",
    "        args=[\n",
    "            {\"visible\": [col == trace.name.split(\" - \")[0] for trace in fig.data]},\n",
    "            ]\n",
    "        ) for col in cols\n",
    "    ]\n",
    "\n",
    "# Configurações do gráfico\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1300,\n",
    "    title={\n",
    "        \"text\": \"BoxPlot\",  # Título do gráfico\n",
    "        \"y\": 0.98,  # Posição vertical do título (0 a 1)\n",
    "        \"x\": 0.5,  # Posição horizontal do título (0 a 1)\n",
    "        \"xanchor\": \"center\",  # Ancoragem horizontal\n",
    "        \"yanchor\": \"top\",  # Ancoragem vertical\n",
    "        \"font\": {\n",
    "            \"family\": \"Arial, sans-serif\",\n",
    "            \"size\": 26,\n",
    "            \"color\": \"black\",\n",
    "            \"weight\": \"bold\",\n",
    "        },\n",
    "    },\n",
    "    margin=dict(l=50, r=20, t=100, b=0),  # Margem da área de plotagem\n",
    "    updatemenus=[  # Botões do Filtro. Método menos eficiente\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=True,\n",
    "            buttons=buttons,\n",
    "            direction=\"left\",\n",
    "            x=0.5,  # Posição horizontal dos botões (0 a 1)\n",
    "            y=1.1,  # Posição vertical dos botões (0 a 1)\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"top\",\n",
    "            active=0,\n",
    "        )\n",
    "    ],\n",
    "    showlegend=False,  # Ocultar a legenda\n",
    ")\n",
    "\n",
    "# Configurar eixo X\n",
    "fig.update_xaxes(\n",
    "    title_text=\"\",\n",
    "    tickfont=dict(family=\"Arial\", size=12, color=\"black\", weight=\"bold\"),\n",
    ")\n",
    "\n",
    "# Configurar eixo Y\n",
    "fig.update_yaxes(\n",
    "    title_text=\"\",\n",
    "    tickfont=dict(family=\"Arial\", size=14, color=\"black\", weight=\"bold\"),\n",
    "    tickformat=\".0f\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Model ML</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "try:\n",
    "    cuda_available = cp.cuda.runtime.getDeviceCount() > 0\n",
    "except Exception:\n",
    "    cuda_available = False\n",
    "\n",
    "# Set tree method\n",
    "tree_method = \"gpu_hist\" if cuda_available else \"hist\"\n",
    "device = \"cuda\" if cuda_available else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Tree Method: {tree_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into features and target\n",
    "X = df_train.drop(columns=[\"rainfall\"])\n",
    "Y = df_train[\"rainfall\"]\n",
    "\n",
    "# Split data into train and test\n",
    "X1, X2, Y1, Y2 = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Resample data\n",
    "X1_resampled, Y1_resampled = ADASYN(random_state=42,n_neighbors=7).fit_resample(X1, Y1)\n",
    "\n",
    "#X1_resampled, Y1_resampled = SMOTE(random_state=42).#fit_resample(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Hyperparameter Tuning\n",
    "def objective(trial):\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        \"device\": device, # Use GPU\n",
    "        \"tree_method\":tree_method, # Optimize for GPU\n",
    "        \"objective\": \"binary:logistic\",  # Binary Classification\n",
    "        \"eval_metric\": \"auc\", # Metric to evaluate\n",
    "        \"random_state\": 42, # Random seed\n",
    "        \"verbosity\": 0, # Verbosity of printing messages\n",
    "        #\"scale_pos_weight\": Y1[Y1 == 0].shape[0] / Y1[Y1 == 1].shape[0], # Control the balance of positive and negative weights\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),  # Number of trees\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10), # Maximum depth of the tree\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),  # Learning rate\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1), # Subsample ratio of the training instances\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1), \n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1), # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),  # Minimum sum of instance weight (hessian) needed in a child\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 0.1),  # L1 regularization term on weights\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.001, 0.1),  # L2 regularization term on weights\n",
    "        \"early_stopping_rounds\": 20, # Early stopping\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    auc_scores = [] # List to store AUC scores\n",
    "\n",
    "    model = xgb.XGBClassifier(**params) # Create model\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # Cross Validation\n",
    "    \n",
    "    # Train model\n",
    "    for train_index, test_index in cv.split(X1_resampled, Y1_resampled):\n",
    "        X_train, X_test = X1_resampled.iloc[train_index], X1_resampled.iloc[test_index]\n",
    "        Y_train, Y_test = Y1_resampled.iloc[train_index], Y1_resampled.iloc[test_index]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            eval_set=[(X_test, Y_test)], # Validation set\n",
    "            verbose=False,\n",
    "        )\n",
    "    \n",
    "        Y_pred = model.predict(X_test)\n",
    "        Y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(Y_test, Y_proba)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"Rainfall_1\") # Maximize AUC score\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True) # Optimize study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print(f\"Best Trial: {trial.number}\")\n",
    "print(f\"ROC AUC: {trial.value:.4f}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Optimization History\n",
    "optuna.visualization.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Parameter Importances\n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best parameters\n",
    "param = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": 0,\n",
    "    \"scale_pos_weight\": Y1[Y1 == 0].shape[0] / Y1[Y1 == 1].shape[0],\n",
    "    \"early_stopping_rounds\": 20,\n",
    "    \"verbose\": False,\n",
    "    **trial.params,\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**param)\n",
    "model.fit(X1, Y1, eval_set=[(X2, Y2)], verbose=False)\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(X2)\n",
    "Y_proba = model.predict_proba(X2)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(Y2, Y_pred)\n",
    "precision = precision_score(Y2, Y_pred)\n",
    "recall = recall_score(Y2, Y_pred)\n",
    "f1 = f1_score(Y2, Y_pred)\n",
    "roc_auc = roc_auc_score(Y2, Y_proba)\n",
    "logloss = log_loss(Y2, Y_proba)\n",
    "\n",
    "print(\"Trained Model:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained Model:\".center(20, \"-\"))\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = model.feature_importances_\n",
    "feature_importance = np.round(feature_importance * 100, 3)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=X.columns,\n",
    "        y=feature_importance,\n",
    "        marker_color=\"blue\",\n",
    "        hovertemplate=\"<b>%{x}:</b> %{y:.2f}%<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Importance\",\n",
    "    title_font_family=\"calibri\",\n",
    "    title_font_size=30,\n",
    "    title_font_color=\"black\",\n",
    "    title_font_weight=\"bold\",\n",
    "    title_x=0.5,\n",
    "    title_y=0.95,\n",
    "    title_pad_t=20,\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Importance\",\n",
    "    xaxis_tickangle=-45,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y2, Y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(Y2, Y_proba) # False Positive Rate, True Positive Rate, Thresholds\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color=\"red\", label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"blue\", linestyle=\"--\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(Y2, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Metrics by Threshold\n",
    "metrics = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    Y_pred_threshold = (Y_proba > threshold).astype(int)\n",
    "    accuracy = accuracy_score(Y2, Y_pred_threshold)\n",
    "    precision = precision_score(Y2, Y_pred_threshold, zero_division=0)\n",
    "    recall = recall_score(Y2, Y_pred_threshold)\n",
    "    f1 = f1_score(Y2, Y_pred_threshold)\n",
    "    roc_auc = roc_auc_score(Y2, Y_proba)\n",
    "    logloss = log_loss(Y2, Y_proba)\n",
    "    metrics.append([accuracy, precision, recall, f1, roc_auc, logloss])\n",
    "\n",
    "metrics = np.array(metrics)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 0], mode=\"lines\", name=\"Accuracy\"))\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 1], mode=\"lines\", name=\"Precision\"))\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 2], mode=\"lines\", name=\"Recall\"))\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 3], mode=\"lines\", name=\"F1\"))\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 4], mode=\"lines\", name=\"ROC AUC\"))\n",
    "fig.add_trace(go.Scatter(x=thresholds, y=metrics[:, 5], mode=\"lines\", name=\"Log Loss\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Metrics by Threshold (ROC Curve)\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    title_font_weight=\"bold\",\n",
    "    xaxis_title=\"Threshold\",\n",
    "    yaxis_title=\"Value\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric with Optimal Threshold\n",
    "optimal_threshold = thresholds[np.argmax(metrics[:, 3])] # F1 Score\n",
    "Y_pred_optimal = (Y_proba > optimal_threshold).astype(int)  # Predict\n",
    "\n",
    "accuracy = accuracy_score(Y2, Y_pred_optimal)\n",
    "precision = precision_score(Y2, Y_pred_optimal, zero_division=0)\n",
    "recall = recall_score(Y2, Y_pred_optimal)\n",
    "f1 = f1_score(Y2, Y_pred_optimal)\n",
    "roc_auc = roc_auc_score(Y2, Y_proba)\n",
    "logloss = log_loss(Y2, Y_proba)\n",
    "\n",
    "print(\"Optimal Threshold:\".center(40, \"-\"))\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")\n",
    "\n",
    "# Confusion Matrix by Optimal Threshold\n",
    "cm = confusion_matrix(Y2, Y_pred_optimal)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix by Optimal Threshold\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 style=\"font-size: 18px;\">Aplicação ML no dataframe de test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", index_col=\"id\")\n",
    "\n",
    "y_pred_test = model.predict(df_test)\n",
    "y_pred_proba_test = model.predict_proba(df_test)[:, 1]\n",
    "\n",
    "df_test[\"rainfall\"] = y_pred_test\n",
    "df_test[\"rainfall_proba\"] = y_pred_proba_test\n",
    "df_test[\"rainfall_proba\"] = df_test[\"rainfall_proba\"].apply(lambda x: round(x * 100, 2))\n",
    "\n",
    "df_test[[\"rainfall\", \"rainfall_proba\"]].to_csv(\"submission.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
